(window.webpackJsonp=window.webpackJsonp||[]).push([[26],{359:function(e,t,a){"use strict";a.r(t);var i=a(0),s=Object(i.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h2",{attrs:{id:"context"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#context"}},[e._v("#")]),e._v(" Context")]),e._v(" "),t("p",[e._v("In the highly competitive automotive industry, quality control is essential to ensure the reliability of vehicles and\nuser safety. A failure in quality control can severely jeopardize safety, result in significant financial costs, and\ncause substantial reputational damage to the company involved.")]),e._v(" "),t("p",[e._v("One of the challenges for Renault is to improve the reliability of quality control for welding seams in automotive body\nmanufacturing. Currently, this inspection is consistently performed by a human operator due to the legal dimension\nrelated to user safety, but can have limitations, such as:")]),e._v(" "),t("ul",[t("li",[e._v("Inconsistent inspection results due to human error.")]),e._v(" "),t("li",[e._v("Detecting micro-defects in real-time.")]),e._v(" "),t("li",[e._v("Consuming manual inspections, slowing down production.")]),e._v(" "),t("li",[e._v("Costs of rework or recalls if defects go unnoticed.")])]),e._v(" "),t("p",[e._v("The key challenge is to develop an AI-based solution that reduces the number of inspections required by the operator\nthrough automated pre-validation, speed up inspections, lowering costs by minimizing rework and recalls.\nFor defect identification, the system should provide the operator with relevant information on the location of the\ndetected defect in the image, hence reducing the control task duration.")]),e._v(" "),t("h2",{attrs:{id:"description"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#description"}},[e._v("#")]),e._v(" Description")]),e._v(" "),t("p",[e._v("A vehicle has many welding seams located at different positions on the vehicle chassis. These welding-seams are named\nc_X.")]),e._v(" "),t("p",[e._v("A weld can have two distinct states:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("OK")]),e._v(": The welding is normal.")]),e._v(" "),t("li",[t("code",[e._v("KO")]),e._v(": The welding has defects.")])]),e._v(" "),t("h2",{attrs:{id:"usecase-objective-intended-purpose"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#usecase-objective-intended-purpose"}},[e._v("#")]),e._v(" Usecase objective (Intended purpose)")]),e._v(" "),t("p",[e._v("The objective is to develop an AI system capable of recognizing whether a welding is acceptable ("),t("code",[e._v("OK")]),e._v(") or not from a\nphoto. A photo that is deemed not "),t("code",[e._v("OK")]),e._v(" is always reviewed by the operator. Therefore, the goal is to maximize the number\nof normal welding that are correctly identified as "),t("code",[e._v("OK")]),e._v(", reducing the number of images that require operator review.")]),e._v(" "),t("p",[e._v("There are also safety constraints on the system's performance: a photo that is actually "),t("code",[e._v("KO")]),e._v(" (not acceptable) must "),t("strong",[e._v("never")]),e._v(" be classified as "),t("code",[e._v("OK")]),e._v(" to ensure it is always reviewed by the operator. Additionally, when a photo is classified\nas "),t("code",[e._v("KO")]),e._v(", the operator would like to receive information about where the defect was detected in the image to help reduce\nthe time spent on the control task.")]),e._v(" "),t("p",[e._v('For images that the AI system cannot confidently classify, it can return an "Unknown" label, meaning the image will also\nbe reviewed by the operator.')]),e._v(" "),t("p",[e._v("This functional behavior is illustrated in the figure below:")]),e._v(" "),t("div",{staticStyle:{"text-align":"center",padding:"40px"}},[t("img",{attrs:{src:"process_new.png",alt:"process",width:"800px"}})]),e._v(" "),t("h2",{attrs:{id:"operational-domain-design-odd-definition"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#operational-domain-design-odd-definition"}},[e._v("#")]),e._v(" Operational Domain Design (ODD) Definition")]),e._v(" "),t("p",[e._v("The Operational Domain Design defines the set of input images for which the AI component is expected to return a\npredicted state.")]),e._v(" "),t("p",[e._v("Here are the conditions and environments in which the AI system is expected to operate effectively and safely:")]),e._v(" "),t("ul",[t("li",[e._v("The luminosity of an image can be between "),t("strong",[e._v("60 and 140 lumens")]),e._v(".")]),e._v(" "),t("li",[e._v("The level of blur (due to vibration of the production line) of an image can be "),t("strong",[e._v("variable")]),e._v(".")]),e._v(" "),t("li",[e._v("The orientation of welding seams can vary in the image with a "),t("strong",[e._v("rotation angle between -10° and 10°")]),e._v(".")]),e._v(" "),t("li",[e._v("The position of the piece in the image can be "),t("strong",[e._v("translated by 5 millimeters")]),e._v(" (corresponding to "),t("strong",[e._v("100 pixels")]),e._v(" in the\nimage depending on seams and camera position).")])]),e._v(" "),t("p",[e._v("For images that are out of the ODD, the AI component shall return "),t("strong",[e._v("“UNKNOWN”")]),e._v(", and the image is sent to the operator.")]),e._v(" "),t("p",[e._v("The operational constraints are as follows:")]),e._v(" "),t("ul",[t("li",[t("strong",[e._v("False negative detections")]),e._v(" (defective welding qualified as "),t("code",[e._v("OK")]),e._v(" by AI system) have a safety cost and shall "),t("strong",[e._v("imperatively be minimized")]),e._v(". This is a "),t("strong",[e._v("primary objective")]),e._v(".")]),e._v(" "),t("li",[t("strong",[e._v("Maximize the accuracy")]),e._v(" of prediction.")]),e._v(" "),t("li",[e._v("Some welding seams are "),t("strong",[e._v("more critical than others")]),e._v(", depending on their position. The level of criticality impacts\nthe cost of false negatives.")])]),e._v(" "),t("h2",{attrs:{id:"quality-criteria"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#quality-criteria"}},[e._v("#")]),e._v(" Quality criteria")]),e._v(" "),t("p",[e._v("The AI component must consider several quality criteria:")]),e._v(" "),t("ul",[t("li",[t("strong",[e._v("Operational cost metrics")]),e._v(": Measure the financial gain (in euros) between a legacy system and the AI system.")]),e._v(" "),t("li",[t("strong",[e._v("Uncertainty metrics")]),e._v(": Measuring the ability of the model to use uncertainty to improve trustworthiness in its\noutput.")]),e._v(" "),t("li",[t("strong",[e._v("Robustness metrics")]),e._v(": Measuring the ability of the model to be invariant to empirical perturbations on input\nimages (blur, luminosity, rotation, translation).")]),e._v(" "),t("li",[t("strong",[e._v("Monitoring metrics")]),e._v(": Measuring the ability of the model to detect if the given input is within the ODD and adapt\nits output accordingly.")]),e._v(" "),t("li",[t("strong",[e._v("Explainability metrics")]),e._v(": Measuring the ability of the model to provide an explanation for its decision to help the\noperator save time during inspection.")])]),e._v(" "),t("p",[e._v("More details about these different criteria will be provided in the coming weeks.")]),e._v(" "),t("h2",{attrs:{id:"dataset"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dataset"}},[e._v("#")]),e._v(" Dataset")]),e._v(" "),t("p",[e._v("The provided dataset has 114231 pictures in full HD (approximately 31 Go of data), with 12 different types of welding\nseams.\nThese images are labelled to indicate if the welding is "),t("code",[e._v("OK")]),e._v(" or "),t("code",[e._v("KO")]),e._v(".\nMost of images are in full HD resolution "),t("code",[e._v("(1920*1080)")]),e._v("  but a part are in "),t("code",[e._v("(960*540)")]),e._v(".\nThis dataset is provided with an additional parquet file that contains metadata of all images.")]),e._v(" "),t("p",[e._v("Here is below some examples of weldings "),t("code",[e._v("OK")]),e._v(" and "),t("code",[e._v("KO")]),e._v(" on two different welding seams "),t("code",[e._v("c10")]),e._v(" and "),t("code",[e._v("c19")]),e._v(".")]),e._v(" "),t("div",{staticStyle:{display:"flex","justify-content":"center",gap:"30%"}},[t("b",[e._v("c10 OK")]),e._v(" "),t("b",[e._v("c19 OK")])]),e._v(" "),t("div",{staticStyle:{display:"flex","justify-content":"center","flex-wrap":"wrap",gap:"5px"}},[t("img",{attrs:{src:"welds/C10_OK.jpg",alt:"process",width:"40%"}}),e._v(" "),t("img",{attrs:{src:"welds/C19_OK.jpg",alt:"c19 ok",width:"40%"}})]),e._v(" "),t("br"),e._v(" "),t("div",{staticStyle:{display:"flex","justify-content":"center",gap:"30%"}},[t("b",[e._v("c10 KO")]),e._v(" "),t("b",[e._v("c19 KO")])]),e._v(" "),t("div",{staticStyle:{display:"flex","justify-content":"center","flex-wrap":"wrap",gap:"5px"}},[t("img",{attrs:{src:"welds/C10_RETOUCHE.jpg",alt:"process",width:"40%"}}),e._v(" "),t("img",{attrs:{src:"welds/C19_RETOUCHE.jpg",alt:"C19 retouche",width:"40%"}})]),e._v(" "),t("br"),e._v(" "),t("br"),e._v(" "),t("br"),e._v(" "),t("p",[e._v('The labeling of welding is done by two types of human annotators: "expert" and "operator.\nThe welding state class, the welding-seams and the type of human annotator are described in a sample metadata file.\nSee next section for detailed description of all available metadata.')]),e._v(" "),t("h2",{attrs:{id:"detailed-description-of-the-meta-data"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#detailed-description-of-the-meta-data"}},[e._v("#")]),e._v(" Detailed description of the meta data")]),e._v(" "),t("p",[e._v('All meta-information are stored in a parquet file named meta_ds.parquet stored in "metadata" folder in the dataset\nfolder. A parquet can be seen as a file representing a dataframe. It can be opened with classical data-analysis python\npackages, like pandas or polars.')]),e._v(" "),t("p",[e._v("The metadata dataframe contains one row per sample, and the dataset includes the following columns:")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Column Name")]),e._v(" "),t("th",[e._v("Description")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[e._v("sample_id")]),e._v(" "),t("td",[e._v('Unique identifier for the sample. It has a syntax of type  "data_X"')])]),e._v(" "),t("tr",[t("td",[e._v("class")]),e._v(" "),t("td",[e._v("The real state of the welding present in the image; this is the ground truth. two values are possible "),t("code",[e._v("OK")]),e._v(" or "),t("code",[e._v("KO")])])]),e._v(" "),t("tr",[t("td",[e._v("timestamp")]),e._v(" "),t("td",[e._v("Datetime where the photo was taken, this is shall not be useful in this challenge")])]),e._v(" "),t("tr",[t("td",[e._v("welding-seams")]),e._v(" "),t("td",[e._v('The name of the welding seam to which the welding belongs. The welding-seams are named "c_X"')])]),e._v(" "),t("tr",[t("td",[e._v("labelling_type")]),e._v(" "),t("td",[e._v('Type of human who annotated the data. two possible values : "expert" or "operator"')])]),e._v(" "),t("tr",[t("td",[e._v("resolution")]),e._v(" "),t("td",[e._v("resolution information of the image [width, height]")])]),e._v(" "),t("tr",[t("td",[e._v("path")]),e._v(" "),t("td",[e._v("internal path of the image in the challenge storage")])]),e._v(" "),t("tr",[t("td",[e._v("sha256")]),e._v(" "),t("td",[e._v("Sha256 of the image . It's a unique hexadecimal key representing image data. This is used to detect alteration of corruption on the storage")])]),e._v(" "),t("tr",[t("td",[e._v("storage_type")]),e._v(" "),t("td",[e._v('Type of storage where sample is stored : "s3" or filesystem')])]),e._v(" "),t("tr",[t("td",[e._v("data-origin")]),e._v(" "),t("td",[e._v("Type of data. This field has two possible values (real or synthetic)")])]),e._v(" "),t("tr",[t("td",[e._v("blur_level")]),e._v(" "),t("td",[e._v("level of blur on the image. The measure was made numerically using opencv library")])]),e._v(" "),t("tr",[t("td",[e._v("blur_class")]),e._v(" "),t("td",[e._v('Class of blur deduced from blur-level field. Two class are considered "blur", and "clean"')])]),e._v(" "),t("tr",[t("td",[e._v("luminosity_level")]),e._v(" "),t("td",[e._v("Luminosity of the image, mesured numerically")])]),e._v(" "),t("tr",[t("td",[e._v("external_path")]),e._v(" "),t("td",[e._v("Url of the image. This url shall be used by Challengers to directly download the sample from the dataset from storage")])]),e._v(" "),t("tr",[t("td",[e._v("OOD_score")]),e._v(" "),t("td",[e._v("Numerical measure of OOD score for the image")])]),e._v(" "),t("tr",[t("td",[e._v("OOD_class")]),e._v(" "),t("td",[e._v("OOD_class labelled by human")])]),e._v(" "),t("tr",[t("td",[e._v("bbox_coord")]),e._v(" "),t("td",[e._v("Coordinates of a bounding box delimiting the weld area on the image. The format is [(x_min,y_min),(x_max,y_max)] where (x_min_ymin) is the upper left corner of the rectangle and(x_max,y_max the lower right corner . This field is available only for 90% of the dataset.")])]),e._v(" "),t("tr",[t("td",[e._v("transfo_order")]),e._v(" "),t("td",[e._v("For synthetic datasets, order of applied multiple perturbations")])]),e._v(" "),t("tr",[t("td",[e._v("source_image_id")]),e._v(" "),t("td",[e._v("For synthetic datasets, source image_id from which the current image was generated")])]),e._v(" "),t("tr",[t("td",[e._v("blur_gen_params")]),e._v(" "),t("td",[e._v("For synthetic datasets, target level of blur in generation process")])]),e._v(" "),t("tr",[t("td",[e._v("luminosity_gen_params")]),e._v(" "),t("td",[e._v("For synthetic datasets, target level of luminosity in generation process")])]),e._v(" "),t("tr",[t("td",[e._v("rotation_gen_params")]),e._v(" "),t("td",[e._v("For synthetic datasets, target level of rotation in generation process")])]),e._v(" "),t("tr",[t("td",[e._v("translation_gen_params")]),e._v(" "),t("td",[e._v("For synthetic datasets, target level of translation in generation process")])])])]),e._v(" "),t("h2",{attrs:{id:"dataset-structure"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dataset-structure"}},[e._v("#")]),e._v(" Dataset structure")]),e._v(" "),t("p",[e._v("The list of all available datasets is accessible in the yaml file named "),t("code",[e._v("datasets_list.yml")]),e._v(" located at the root of\nthe storage. It contains the names of all datasets included in the challenge (ds_name_1, ds_name_2 ..).")]),e._v(" "),t("p",[e._v("There is one subfolder by dataset. In each dataset folder, images are organized hierarchically based on the following\nfields: welding-seams -> human_annotator.")]),e._v(" "),t("p",[e._v("Each dataset has a metadata folder containing a single parquet file named "),t("code",[e._v("meta_ds.parquet")]),e._v(" with all meta\ninformation of all sample present in the dataset.")]),e._v(" "),t("p",[e._v("Thus, the datasets storage has the following structure:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v(".\n├── datasets_list.yml\n├── datasets\n│   ├── ds_name_1\n│   │   ├── metadata\n│   │   |   |──meta_ds.parquet\n│   │   ├── cX\n│   │   │   │── expert\n│   │   │   │   |── sample_X.jpeg\n│   │   │   │   |── sample_Y.jpeg\n│   │   │   │   |── sample_Z.jpeg\n│   │   │   │   |── ..\n│   │   │   │── operator\n│   │   │   │   |── sample_X.jpeg\n│   │   │   │   |── sample_Y.jpeg\n│   │   │   │   |── sample_Z.jpeg\n│   │   │   │   |── ..\n│   │   ├── cY\n│   │   │   │── expert\n│   │   │   │   |── sample_X.jpeg\n│   │   │   │   |── sample_Y.jpeg\n│   │   │   │   |── sample_Z.jpeg\n│   │   │   │   |── ..\n|         ..\n│   ├── ds_name_2\n│   │   ├── metadata\n│   │   |   |──meta_ds.parquet\n│   │   ├── c102\n│   │   │   │── expert\n│   │   │   │   |── sample_X.jpeg\n│   │   │   │   |── sample_Y.jpeg\n│   │   │   │   |── sample_Z.jpeg\n│   │   │   │   |── ..\n│   │   │   │── operator\n│   │   │   │   |── sample_X.jpeg\n│   │   │   │   |── sample_Y.jpeg\n│   │   │   │   |── sample_Z.jpeg\n│   │   │   │   |── ..\n│   │   ├── c27.2\n│   │   │   │── labelling-type\n│   │   │   │   |── sample_X.jpeg\n│   │   │   │   |── sample_Y.jpeg\n│   │   │   │   |── sample_Z.jpeg\n│   │   │   │   |── ..\n")])])]),t("h2",{attrs:{id:"dataset-global-statistics"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dataset-global-statistics"}},[e._v("#")]),e._v(" Dataset global statistics")]),e._v(" "),t("p",[e._v("Number of samples : 114321 images")]),e._v(" "),t("ul",[t("li",[e._v("76528 images in full HD resolution  (1920*1080)")]),e._v(" "),t("li",[e._v("38202 images in resolution (960*540)")])]),e._v(" "),t("p",[e._v("class repartition:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("OK")]),e._v(":   98,60 %")]),e._v(" "),t("li",[t("code",[e._v("KO")]),e._v(":   1.40 %")])]),e._v(" "),t("h2",{attrs:{id:"contact"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#contact"}},[e._v("#")]),e._v(" Contact")]),e._v(" "),t("p",[e._v("email: "),t("a",{attrs:{href:"mailto:support@confiance.ai"}},[e._v("Foundation")])]),e._v(" "),t("br"),e._v(" "),t("br"),e._v(" "),t("br"),e._v(" "),t("br"),e._v(" "),t("br")])}),[],!1,null,null,null);t.default=s.exports}}]);